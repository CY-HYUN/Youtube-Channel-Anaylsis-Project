# ì‚¬ìš© ì˜ˆì‹œ ê°€ì´ë“œ

## ê°œìš”

ì´ ë¬¸ì„œëŠ” YouTube Channel Analysis Projectì˜ ë‹¤ì–‘í•œ ì‚¬ìš© ë°©ë²•ê³¼ ì‹¤ì œ ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# 1. ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/your-username/Youtube-Channel-Analysis-Project.git
cd Youtube-Channel-Analysis-Project

# 2. ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# 3. API í‚¤ ì„¤ì •
export YOUTUBE_API_KEY="your_youtube_api_key_here"
```

### 2. ê¸°ë³¸ ì‹¤í–‰

```bash
# ëª¨ë“  ë‹¨ê³„ ì‹¤í–‰ (ë°ì´í„° ìˆ˜ì§‘ â†’ ë¶„ì„ â†’ ì‹œê°í™”)
python main.py --mode all --channel-id UCuTITJp_8VXjjthWdPdmwKA

# íŠ¹ì • ë‹¨ê³„ë§Œ ì‹¤í–‰
python main.py --mode collect --channel-id UCuTITJp_8VXjjthWdPdmwKA
python main.py --mode analyze
python main.py --mode visualize
```

## ìƒì„¸ ì‚¬ìš© ë°©ë²•

### ë°ì´í„° ìˆ˜ì§‘

#### ë‹¨ì¼ ì±„ë„ ë¶„ì„
```bash
python main.py --mode collect \
    --channel-id UCuTITJp_8VXjjthWdPdmwKA \
    --max-videos 100
```

#### ì—¬ëŸ¬ ì±„ë„ ë™ì‹œ ë¶„ì„
```bash
python main.py --mode collect \
    --channel-id UCuTITJp_8VXjjthWdPdmwKA \
    --channel-id UC_x5XG1OV2P6uZZ5FSM9Ttw \
    --channel-id UCEDXXCXj5UKKkVNTZUKLKtQ \
    --max-videos 50
```

#### í”„ë¡œê·¸ë˜ë° ë°©ì‹ ì‚¬ìš©
```python
from src.data_collection.youtube_api import YouTubeDataCollector
from config.config import Config

# ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
api_key = Config.get_api_key()
collector = YouTubeDataCollector(api_key)

# ì±„ë„ ë°ì´í„° ìˆ˜ì§‘
channel_id = "UCuTITJp_8VXjjthWdPdmwKA"
data = collector.collect_channel_data(channel_id, max_videos=100)

# CSVë¡œ ì €ì¥
collector.save_data_to_csv(data, "data/raw")
```

### ë°ì´í„° ë¶„ì„

#### ê¸°ë³¸ ë¶„ì„
```python
from src.analysis.channel_analyzer import ChannelAnalyzer

# ë¶„ì„ê¸° ì´ˆê¸°í™”
analyzer = ChannelAnalyzer(
    "data/raw/Channel_Name_channel_info.csv",
    "data/raw/Channel_Name_videos.csv"
)

# ì±„ë„ ìš”ì•½ ì •ë³´
summary = analyzer.get_channel_summary()
print(f"ì±„ë„ëª…: {summary['channel_name']}")
print(f"êµ¬ë…ì ìˆ˜: {summary['subscriber_count']:,}")
print(f"ì´ ì˜ìƒ ìˆ˜: {summary['total_videos']:,}")

# ì„±ê³¼ í†µê³„
performance = analyzer.get_video_performance_stats()
print(f"í‰ê·  ì¡°íšŒìˆ˜: {performance['average_views']:,.0f}")
print(f"í‰ê·  ì°¸ì—¬ìœ¨: {performance['average_engagement_rate']:.2f}%")

# ìƒìœ„ ì„±ê³¼ ì˜ìƒ
top_videos = analyzer.get_top_performing_videos(n=10, metric='views')
print("\\n=== ìƒìœ„ ì¡°íšŒìˆ˜ ì˜ìƒ ===")
for idx, row in top_videos.iterrows():
    title = row['snippet.title'][:50] + "..." if len(row['snippet.title']) > 50 else row['snippet.title']
    views = row['statistics.viewCount']
    print(f"{title}: {views:,} views")
```

#### ê³ ê¸‰ ë¶„ì„
```python
# ì—…ë¡œë“œ ë¹ˆë„ ë¶„ì„
frequency_analysis = analyzer.get_upload_frequency_analysis()
print(f"ì›”í‰ê·  ì—…ë¡œë“œ: {frequency_analysis['average_monthly_uploads']:.1f}ê°œ")
print(f"ê°€ì¥ í™œë°œí•œ ìš”ì¼: {frequency_analysis['most_active_weekday']}")

# ì½˜í…ì¸  ê¸¸ì´ ë¶„ì„
duration_analysis = analyzer.get_content_duration_analysis()
print(f"í‰ê·  ì˜ìƒ ê¸¸ì´: {duration_analysis['average_duration_minutes']:.1f}ë¶„")

# AI ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
insights = analyzer.generate_insights()
for insight in insights:
    print(f"ğŸ’¡ {insight}")
```

### ë°ì´í„° ì‹œê°í™”

#### ê¸°ë³¸ ì‹œê°í™”
```python
from src.visualization.charts import YouTubeVisualizer
import pandas as pd

# ì‹œê°í™” ë„êµ¬ ì´ˆê¸°í™”
visualizer = YouTubeVisualizer()

# ë°ì´í„° ë¡œë“œ
videos_df = pd.read_csv("data/raw/Channel_Name_videos.csv")

# ìƒìœ„ ì„±ê³¼ ì˜ìƒ ì°¨íŠ¸
fig = visualizer.plot_video_performance(videos_df, metric='views', top_n=15)
fig.savefig('top_videos.png', dpi=300, bbox_inches='tight')

# ì—…ë¡œë“œ ë¹ˆë„ ë¶„ì„
fig = visualizer.plot_upload_frequency(videos_df)
fig.savefig('upload_frequency.png', dpi=300, bbox_inches='tight')

# ì°¸ì—¬ë„ ë¶„ì„
fig = visualizer.plot_engagement_analysis(videos_df)
fig.savefig('engagement_analysis.png', dpi=300, bbox_inches='tight')
```

#### ëª¨ë“  ì°¨íŠ¸ í•œ ë²ˆì— ìƒì„±
```python
# ëª¨ë“  ì‹œê°í™”ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ê³  ì €ì¥
visualizer.save_all_charts(videos_df, output_dir="visualizations/channel_name")
```

## ì‹¤ì œ ë¶„ì„ ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ê¸°ìˆ  êµìœ¡ ì±„ë„ ë¶„ì„

```bash
# 1. ë°ì´í„° ìˆ˜ì§‘
python main.py --mode collect --channel-id UC_tech_channel_id --max-videos 200

# 2. ì‹¤í–‰ ê²°ê³¼ ì˜ˆì‹œ
```

**ì±„ë„ ìš”ì•½:**
- ì±„ë„ëª…: Tech Education Hub
- êµ¬ë…ì: 1,200,000ëª…
- ì´ ì˜ìƒ: 500ê°œ
- ì´ ì¡°íšŒìˆ˜: 50,000,000íšŒ

**ì„±ê³¼ ë¶„ì„:**
- í‰ê·  ì¡°íšŒìˆ˜: 100,000íšŒ
- ìµœê³  ì¡°íšŒìˆ˜: 1,500,000íšŒ
- í‰ê·  ì°¸ì—¬ìœ¨: 6.8%
- ì›”í‰ê·  ì—…ë¡œë“œ: 12ê°œ

**ì£¼ìš” ì¸ì‚¬ì´íŠ¸:**
- ğŸ’¡ ìµœê³  ì¡°íšŒìˆ˜ ì˜ìƒì´ í‰ê· ë³´ë‹¤ 15ë°° ë†’ì•„ ë°”ì´ëŸ´ ì½˜í…ì¸  íŠ¹ì„± ë¶„ì„ í•„ìš”
- ğŸ’¡ í™”ìš”ì¼ì— ê°€ì¥ ë§ì´ ì—…ë¡œë“œí•˜ëŠ” íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤
- ğŸ’¡ 20-30ë¶„ ê¸¸ì´ì˜ ì˜ìƒì´ ê°€ì¥ ë†’ì€ í‰ê·  ì¡°íšŒìˆ˜ë¥¼ ê¸°ë¡

### ì˜ˆì‹œ 2: ì—¬ëŸ¬ ì±„ë„ ë¹„êµ ë¶„ì„

```python
# ì—¬ëŸ¬ ì±„ë„ì˜ ì„±ê³¼ ë¹„êµ
channels = [
    ("Tech Channel A", "UCxxxxxxxxxxxx"),
    ("Tech Channel B", "UCyyyyyyyyyyyy"),
    ("Tech Channel C", "UCzzzzzzzzzzzz")
]

comparison_data = []

for name, channel_id in channels:
    # ê° ì±„ë„ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„
    data = collector.collect_channel_data(channel_id)
    analyzer = ChannelAnalyzer(f"{name}_channel_info.csv", f"{name}_videos.csv")

    summary = analyzer.get_channel_summary()
    performance = analyzer.get_video_performance_stats()

    comparison_data.append({
        'channel': name,
        'subscribers': summary['subscriber_count'],
        'avg_views': performance['average_views'],
        'engagement_rate': performance['average_engagement_rate']
    })

# ë¹„êµ ê²°ê³¼ ì¶œë ¥
import pandas as pd
comparison_df = pd.DataFrame(comparison_data)
print(comparison_df)
```

### ì˜ˆì‹œ 3: ì‹œê°„ë³„ íŠ¸ë Œë“œ ë¶„ì„

```python
# ì›”ë³„ ì„±ê³¼ íŠ¸ë Œë“œ ë¶„ì„
monthly_performance = videos_df.groupby(
    videos_df['published_date'].dt.to_period('M')
).agg({
    'statistics.viewCount': 'mean',
    'statistics.likeCount': 'mean',
    'statistics.commentCount': 'mean'
})

# íŠ¸ë Œë“œ ì‹œê°í™”
import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(12, 6))
monthly_performance['statistics.viewCount'].plot(ax=ax, marker='o')
ax.set_title('Monthly Average Views Trend')
ax.set_ylabel('Average Views')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('monthly_trend.png', dpi=300)
```

## ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì˜ˆì‹œ

### ì¼ì¼ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸

```python
#!/usr/bin/env python3
"""
daily_monitor.py - ì¼ì¼ ì±„ë„ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸
"""

import schedule
import time
from datetime import datetime
from src.data_collection.youtube_api import YouTubeDataCollector
from src.analysis.channel_analyzer import ChannelAnalyzer

def daily_analysis():
    """ì¼ì¼ ë¶„ì„ ì‹¤í–‰"""
    print(f"[{datetime.now()}] ì¼ì¼ ë¶„ì„ ì‹œì‘")

    # ëª¨ë‹ˆí„°ë§í•  ì±„ë„ ëª©ë¡
    channels = ["UCuTITJp_8VXjjthWdPdmwKA", "UC_x5XG1OV2P6uZZ5FSM9Ttw"]

    for channel_id in channels:
        try:
            # ìµœì‹  ë°ì´í„° ìˆ˜ì§‘ (ìµœê·¼ 20ê°œ ì˜ìƒë§Œ)
            collector = YouTubeDataCollector(api_key)
            data = collector.collect_channel_data(channel_id, max_videos=20)

            # ê°„ë‹¨í•œ ë¶„ì„
            analyzer = ChannelAnalyzer(
                f"temp_{channel_id}_channel.csv",
                f"temp_{channel_id}_videos.csv"
            )

            summary = analyzer.get_channel_summary()
            performance = analyzer.get_video_performance_stats()

            print(f"ì±„ë„: {summary['channel_name']}")
            print(f"ìµœê·¼ ì˜ìƒ í‰ê·  ì¡°íšŒìˆ˜: {performance['average_views']:,.0f}")

        except Exception as e:
            print(f"ì±„ë„ {channel_id} ë¶„ì„ ì‹¤íŒ¨: {e}")

# ë§¤ì¼ ì˜¤ì „ 9ì‹œì— ì‹¤í–‰
schedule.every().day.at("09:00").do(daily_analysis)

if __name__ == "__main__":
    while True:
        schedule.run_pending()
        time.sleep(3600)  # 1ì‹œê°„ë§ˆë‹¤ í™•ì¸
```

## ì„±ëŠ¥ ìµœì í™” íŒ

### 1. API í˜¸ì¶œ ìµœì í™”
```python
# ë°°ì¹˜ ì²˜ë¦¬ë¡œ API í˜¸ì¶œ ìµœì†Œí™”
video_ids = [video['id'] for video in video_list]
batch_size = 50  # API ìµœëŒ€ í—ˆìš©ëŸ‰

for i in range(0, len(video_ids), batch_size):
    batch = video_ids[i:i+batch_size]
    video_details = collector.get_video_details(batch)
    time.sleep(0.1)  # API í˜¸ì¶œ ì œí•œ ë°©ì§€
```

### 2. ë°ì´í„° ìºì‹±
```python
import pickle
from pathlib import Path

# ë°ì´í„° ìºì‹œ ì €ì¥
def save_cache(data, filename):
    cache_dir = Path("cache")
    cache_dir.mkdir(exist_ok=True)

    with open(cache_dir / filename, 'wb') as f:
        pickle.dump(data, f)

# ìºì‹œ ë¡œë“œ
def load_cache(filename):
    cache_path = Path("cache") / filename
    if cache_path.exists():
        with open(cache_path, 'rb') as f:
            return pickle.load(f)
    return None
```

### 3. ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬
```python
# ì²­í¬ ë‹¨ìœ„ë¡œ ë°ì´í„° ì²˜ë¦¬
chunk_size = 1000
for chunk in pd.read_csv("large_video_data.csv", chunksize=chunk_size):
    # ê° ì²­í¬ì— ëŒ€í•´ ë¶„ì„ ìˆ˜í–‰
    result = analyze_chunk(chunk)
    save_chunk_result(result)
```

## ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ì¼ë°˜ì ì¸ ì˜¤ë¥˜ì™€ í•´ê²°ì±…

**1. API í‚¤ ê´€ë ¨ ì˜¤ë¥˜**
```
ValueError: YouTube API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
```
**í•´ê²°ì±…:**
- í™˜ê²½ë³€ìˆ˜ `YOUTUBE_API_KEY` ì„¤ì • í™•ì¸
- API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ Google Cloud Consoleì—ì„œ í™•ì¸

**2. í• ë‹¹ëŸ‰ ì´ˆê³¼ ì˜¤ë¥˜**
```
403 Forbidden: Quota exceeded
```
**í•´ê²°ì±…:**
- ë‹¤ìŒë‚ ê¹Œì§€ ëŒ€ê¸°í•˜ê±°ë‚˜ í• ë‹¹ëŸ‰ ì¦ì•¡ ìš”ì²­
- API í˜¸ì¶œ ìµœì í™”ë¡œ ì‚¬ìš©ëŸ‰ ì¤„ì´ê¸°

**3. ë°ì´í„° íŒŒì¼ ì—†ìŒ**
```
FileNotFoundError: [Errno 2] No such file or directory
```
**í•´ê²°ì±…:**
- ë°ì´í„° ìˆ˜ì§‘ ë‹¨ê³„ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
- íŒŒì¼ ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸

### ë””ë²„ê¹… ëª¨ë“œ ì‚¬ìš©

```python
import logging

# ë””ë²„ê·¸ ë¡œê·¸ í™œì„±í™”
logging.basicConfig(level=logging.DEBUG)

# ë˜ëŠ” ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ
python main.py --mode all --channel-id UCxxxx --debug
```

## ì¶”ê°€ ìë£Œ

- [YouTube Data API v3 ë¬¸ì„œ](https://developers.google.com/youtube/v3)
- [pandas ê³µì‹ ë¬¸ì„œ](https://pandas.pydata.org/docs/)
- [matplotlib íŠœí† ë¦¬ì–¼](https://matplotlib.org/tutorials/)
- [seaborn ê°¤ëŸ¬ë¦¬](https://seaborn.pydata.org/examples/)